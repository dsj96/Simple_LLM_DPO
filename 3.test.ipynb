{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a36f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S184.04=97.13--37.65+49.26E'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run common.ipynb\n",
    "\n",
    "tokenizer.decode(tokenizer.get_data(third_number=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f646376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelGEN(\n",
       "  (feature): LlamaModel(\n",
       "    (embed_tokens): Embedding(22, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (o_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (up_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (down_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (fc_out): Linear(in_features=64, out_features=22, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dpo = torch.load('dpo.model')\n",
    "model_dpo.to(device)\n",
    "model_dpo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9d94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S59.08= -43.54/-96.30+58.20E 0.42787123572169605\n",
      "S86.25= -76.00+68.12+99.21E 5.079999999999998\n",
      "S399.59= 94.09*4.18+78.57E 72.27620000000002\n",
      "S61.42= 93.88+9.01+-53.59E 12.120000000000005\n",
      "S63.39= -79.70/-96.54+62.59E 0.025564532836135356\n",
      "S-4389.33= 49.30*-86.85+-8.44E 99.1850000000004\n",
      "S-6603.37= -78.70*81.01+-74.80E 153.08299999999872\n",
      "S-130.09= -97.88+-37.18+11.58E 6.609999999999999\n",
      "S9.26= 1.06+99.14+-70.34E 20.6\n",
      "S61.99= 91.78/84.61+61.63E 0.7247417562935823\n",
      "S90.03= 16.64+41.20+27.95E 4.239999999999995\n",
      "S-37.72= -11.83--27.41+-47.54E 5.759999999999998\n",
      "S112.38= 17.30+23.30+78.97E 7.189999999999998\n",
      "S471.40= -7.66*-76.95+-30.70E 87.33699999999999\n",
      "S-17.67= -49.66/2.63+-1.60E 2.8121292775665374\n",
      "S3268.23= 43.54*72.95+-67.23E 159.2170000000001\n",
      "S25.38= 55.42-88.85+62.40E 3.590000000000007\n",
      "S-134.31= -69.52-27.31+-29.32E 8.159999999999997\n",
      "S-31.26= -4.47+-56.97+28.35E 1.8299999999999947\n",
      "S-126.99= -16.59-69.76+-49.76E 9.120000000000019\n",
      "S-3776.09= 60.69*-60.19+51.56E 174.7189000000003\n",
      "S-93.66= -98.26-84.03+98.77E 10.139999999999972\n",
      "S-14.23= -5.47+-19.02+6.71E 3.549999999999997\n",
      "S103.51= /32.67--11.89+90.67E 103.51\n",
      "S-69.05= -77.66+-37.85+64.72E 18.260000000000005\n",
      "S-87.15= -88.23--32.20+-32.76E 1.6399999999999864\n",
      "S23.96= -1.28-86.71+97.84E 14.109999999999992\n",
      "S47.59= 26.06/-72.29+47.26E 0.6904924609212912\n",
      "S12.78= -49.86/7.89+9.43E 9.66939163498099\n",
      "S-20.94= 13.98-97.85+63.49E 0.5600000000000129\n",
      "S-7.33= -36.72-20.13+49.47E 0.04999999999999538\n",
      "S-189.27= -96.69+-79.28+-0.74E 12.560000000000002\n",
      "S159.33= 12.28*11.51+-17.23E 35.217200000000034\n",
      "S149.41= 18.73+95.68+35.04E 0.040000000000020464\n",
      "S-64.17= 11.07+-10.91+-59.09E 5.239999999999995\n",
      "S-109.93= -55.91-91.22+44.14E 6.940000000000012\n",
      "S4.70= 87.69/76.90+4.54E 0.980312093628088\n",
      "S-141.31= -92.17-69.02+17.36E 2.519999999999982\n",
      "S-64.28= -9.24+-65.35+37.24E 26.930000000000014\n",
      "S-23.03= -20.10+-9.74+9.90E 3.0899999999999963\n",
      "S111.26= -1.83*43.62+-56.30E 247.38459999999998\n",
      "S-150.12= 35.21-96.41+-90.42E 1.5\n",
      "S147.04= 94.70+-4.61+55.41E 1.539999999999992\n",
      "S-150.94= -85.62+-47.50+-15.46E 2.359999999999985\n",
      "S-10.62= 79.93/52.52+-12.77E 0.6281035795887284\n",
      "S-1227.83= -32.46*42.22+-29.39E 172.02120000000014\n",
      "S-7492.52= -96.49*74.29+-45.82E 278.45790000000034\n",
      "S-71.27= -89.89--81.22+-61.96E 0.6400000000000006\n",
      "S12.98= -7.07/48.57+11.60E 1.5255631047972003\n",
      "S-77.92= -56.29+-45.53+31.45E 7.550000000000011\n",
      "S-168.82= -46.26+-32.96+-86.22E 3.3799999999999955\n",
      "S1326.63= -29.21*-48.49+57.34E 147.10289999999986\n",
      "S-86.43= -50.03+-21.24+-12.70E 2.460000000000008\n",
      "S-1.58= 95.07+-86.75+-2.20E 7.699999999999993\n",
      "S21.66= 2.69+-22.18+38.80E 2.3500000000000014\n",
      "S55.23= -11.62+19.77+50.74E 3.6600000000000037\n",
      "S-1323.18= -94.34*14.26+-69.97E 92.0784000000001\n",
      "S6266.42= -70.79*-89.85+47.26E 141.32150000000001\n",
      "S-156.89= -62.81+-92.44+-1.81E 0.17000000000001592\n",
      "S-19.68= 72.71/-18.44+-17.43E 1.6930585683297181\n",
      "S142.96= 84.18-1.91+67.70E 7.010000000000019\n",
      "S-59.74= 77.77/-23.44+-56.40E 0.02216723549488364\n",
      "S-12.54= 45.12+0.94+-48.30E 10.299999999999997\n",
      "S-133.66= 14.73+-76.94+-70.55E 0.9000000000000057\n"
     ]
    }
   ],
   "source": [
    "#随机一批数据\n",
    "input_ids = [tokenizer.get_data(third_number=True) for i in range(64)]\n",
    "\n",
    "#切分成question和answer\n",
    "split = [i.index(tokenizer.encoder['=']) + 1 for i in input_ids]\n",
    "question = [input_ids[i][:split[i]] for i in range(len(input_ids))]\n",
    "answer = [input_ids[i][split[i]:] for i in range(len(input_ids))]\n",
    "\n",
    "#根据question生成predict\n",
    "input_ids = [torch.LongTensor(i).unsqueeze(0).to(device) for i in question]\n",
    "predict = [generate(model_dpo, i) for i in input_ids]\n",
    "\n",
    "#裁剪,只要生成的部分\n",
    "predict = [p[0].tolist()[len(q):] for p, q in zip(predict, question)]\n",
    "\n",
    "#解码成文本\n",
    "question = [tokenizer.decode(i) for i in question]\n",
    "answer = [tokenizer.decode(i) for i in answer]\n",
    "predict = [tokenizer.decode(i) for i in predict]\n",
    "\n",
    "for q, a, p in zip(question, answer, predict):\n",
    "    try:\n",
    "        diff = abs(float(q[1:-1]) - eval(p[:p.index('E')]))\n",
    "    except:\n",
    "        diff = abs(float(q[1:-1]))\n",
    "\n",
    "    print(q, p, diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt2]",
   "language": "python",
   "name": "conda-env-pt2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
